{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain-google-genai python-dotenv langchain-core pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multimodal Inputs with Google Gemini\n",
    "====================================\n",
    "\n",
    "In this notebook, we learn:\n",
    "- Sending images to Gemini models\n",
    "- Handling different image formats and sources\n",
    "- Combining text and image prompts\n",
    "- Best practices for multimodal applications\n",
    "\n",
    "Official documentation:\n",
    "- LangChain Multimodal: https://python.langchain.com/docs/concepts/multimodality/\n",
    "- Google Gemini Vision: https://ai.google.dev/gemini-api/docs/vision\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import io\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from PIL import Image\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Gemini Pro model (supports multimodal)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",  # Use 2.0 flash for multimodal\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Gemini 2.0 Flash model initialized for multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMAGE FROM URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üñºÔ∏è 1. Analyzing Image from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image description: The image shows a suitcase. The suitcase is a light blue color. It has a black retractable handle at the top and a smaller black handle on the side. It also has four black wheels.\n",
      "\n",
      "As it is a suitcase, it is designed to be traveled with.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_image_message_from_url(image_url, text_prompt):\n",
    "    \"\"\"Create a message with image from URL and text prompt\"\"\"\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": text_prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "        ]\n",
    "    )\n",
    "    return message\n",
    "\n",
    "\n",
    "# Example with a public image URL (Google Cloud sample image)\n",
    "image_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\"\n",
    "\n",
    "image_message = create_image_message_from_url(\n",
    "    image_url,\n",
    "    \"Describe what you see in this image. What are colors and can I travel with it?\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = llm.invoke([image_message])\n",
    "    print(f\"Image description: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing image from URL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Image URL analysis may have limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IMAGE FROM BASE64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì∏ 2. Processing Base64 Encoded Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image analysis: The image is a light blue color. It's a pale and soft shade of blue, almost pastel in tone. It appears uniform and consistent throughout the image.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Encode local image to base64\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found at {image_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_image_message_from_base64(base64_image, text_prompt, image_type=\"jpeg\"):\n",
    "    \"\"\"Create message with base64 image\"\"\"\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": text_prompt},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/{image_type};base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message\n",
    "\n",
    "# Create a simple test image programmatically\n",
    "\n",
    "\n",
    "def create_test_image():\n",
    "    \"\"\"Create a simple test image\"\"\"\n",
    "    img = Image.new('RGB', (200, 100), color='lightblue')\n",
    "\n",
    "    # Save to bytes\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format='PNG')\n",
    "    img_bytes.seek(0)\n",
    "\n",
    "    # Encode to base64\n",
    "    return base64.b64encode(img_bytes.getvalue()).decode('utf-8')\n",
    "\n",
    "\n",
    "# Create and analyze test image\n",
    "test_image_b64 = create_test_image()\n",
    "test_message = create_image_message_from_base64(\n",
    "    test_image_b64,\n",
    "    \"What color is this image? Describe its characteristics.\",\n",
    "    \"png\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = llm.invoke([test_message])\n",
    "    print(f\"Test image analysis: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing base64 image: {e}\")\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MULTIMODAL PROMPT TEMPLATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\nüìù 3. Multimodal Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template-based analysis: Here is a detailed analysis of the image:\n",
      "\n",
      "**Overall Impression:**\n",
      "The image is a studio shot featuring a light blue suitcase. The composition is clean and simple, focusing entirely on the product. The lighting is soft and even, creating a professional and appealing presentation.\n",
      "\n",
      "**Visual Elements:**\n",
      "\n",
      "*   **Subject:** The main subject is a modern, hard-shell suitcase with a light blue finish. It has a telescoping handle, a side handle, and four wheels. The suitcase's design features vertical recessed lines on its front panel.\n",
      "*   **Composition:** The suitcase is positioned centrally in the frame. This symmetrical composition creates a sense of balance and draws the eye directly to the product.\n",
      "*   **Background:** The background is a plain, light grey or off-white wall, providing a neutral backdrop that doesn't distract from the suitcase.\n",
      "*   **Foreground:** The suitcase rests on a white or light-colored surface, likely a table or platform, which reflects some light and helps to separate the suitcase from the background.\n",
      "\n",
      "**Colors:**\n",
      "\n",
      "*   **Dominant Color:** The light blue of the suitcase is the most prominent color in the image.\n",
      "*   **Accent Colors:** Black accents appear on the telescoping handle, side handle, and wheels, providing contrast against the light blue.\n",
      "*   **Neutral Palette:** The light grey/off-white background and white surface create a neutral palette that allows the suitcase to stand out without competing colors.\n",
      "\n",
      "**Lighting:**\n",
      "\n",
      "*   **Type:** The lighting appears to be soft and diffused, likely achieved with studio lighting equipment.\n",
      "*   **Shadows:** Shadows are minimal, suggesting a well-lit environment with multiple light sources or diffusion panels to reduce harsh shadows.\n",
      "*   **Highlights:** Subtle highlights on the suitcase's surface indicate the direction of the light source and add dimension to the object.\n",
      "\n",
      "**Mood:**\n",
      "\n",
      "*   **Clean and Modern:** The image conveys a sense of cleanliness and modernity due to the minimalist composition, smooth surfaces, and soft lighting.\n",
      "*   **Professional:** The overall presentation is professional and suitable for advertising or product display purposes.\n",
      "*   **Calm:** The light, muted colors and balanced composition evoke a calm and understated feeling.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a template for image analysis\n",
    "multimodal_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert image analyst. Provide detailed, accurate descriptions.\"),\n",
    "    (\"human\", [\n",
    "        {\"type\": \"text\", \"text\": \"Analyze this image for {analysis_type}. Focus on {focus_areas}.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": \"{image_url}\"}}\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Test the template (with a safe fallback)\n",
    "template_input = {\n",
    "    \"analysis_type\": \"composition and colors\",\n",
    "    \"focus_areas\": \"visual elements, lighting, and overall mood\",\n",
    "    \"image_url\": \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    formatted_messages = multimodal_template.format_messages(**template_input)\n",
    "    response = llm.invoke(formatted_messages)\n",
    "    print(f\"Template-based analysis: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Template analysis error: {e}\")\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. COMBINING MULTIPLE IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\nüñºÔ∏èüñºÔ∏è 4. Analyzing Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-image comparison: Okay, let's break down the differences between the two images.\n",
      "\n",
      "**Image 1: Suitcase**\n",
      "\n",
      "*   **Style:** Clean, minimalist, product-focused, commercial.\n",
      "*   **Purpose:** To showcase the suitcase, its features, and design, likely for advertising or e-commerce.\n",
      "*   **Visual Elements:**\n",
      "    *   **Subject:** A single, light blue suitcase.\n",
      "    *   **Composition:** Centered, symmetrical, straightforward.\n",
      "    *   **Lighting:** Even, diffused, to highlight the product's details without harsh shadows.\n",
      "    *   **Color Palette:** Predominantly light blue and neutral tones (white/gray background).\n",
      "    *   **Texture:** Focus on the smooth, hard texture of the suitcase.\n",
      "    *   **Focus:** Sharp, clear focus on the entire suitcase.\n",
      "\n",
      "**Image 2: Blueberry Scones**\n",
      "\n",
      "*   **Style:** Rustic, food-focused, lifestyle, artistic.\n",
      "*   **Purpose:** To evoke a feeling of warmth, indulgence, and home-baked goodness, often for social media, blogs, or cookbooks.\n",
      "*   **Visual Elements:**\n",
      "    *   **Subject:** Blueberry scones, coffee, blueberries, and flowers.\n",
      "    *   **Composition:** Asymmetrical, more dynamic and \"natural-looking.\" Utilizes the Rule of Thirds.\n",
      "    *   **Lighting:** More dramatic, with highlights and shadows to create depth and texture. Can be natural light.\n",
      "    *   **Color Palette:** Richer, more varied, with blues, purples, pinks, and browns.\n",
      "    *   **Texture:** Emphasis on the crumbly texture of the scones, the smooth blueberries, and the delicate flowers.\n",
      "    *   **Focus:** Selective focus, drawing attention to certain elements (e.g., a scone or the coffee cup) while blurring others.\n",
      "\n",
      "**Key Differences Summarized:**\n",
      "\n",
      "| Feature        | Suitcase Image                               | Blueberry Scones Image                           |\n",
      "|----------------|---------------------------------------------|-------------------------------------------------|\n",
      "| **Style**      | Minimalist, Product-Focused, Commercial     | Rustic, Food-Focused, Lifestyle, Artistic       |\n",
      "| **Purpose**    | Product Advertisement/E-commerce            | Evoke Emotion, Food Photography, Social Media |\n",
      "| **Composition** | Centered, Symmetrical                       | Asymmetrical, Dynamic                          |\n",
      "| **Lighting**   | Even, Diffused                               | Dramatic, Highlights & Shadows                   |\n",
      "| **Color**      | Limited, Neutral Tones                      | Rich, Varied                                    |\n",
      "| **Texture**    | Smooth, Hard                               | Crumbly, Smooth, Delicate                       |\n",
      "| **Focus**      | Sharp Overall                               | Selective Focus                                  |\n",
      "\n",
      "In essence, the suitcase image is about clearly presenting a product, while the scones image is about creating a mood and appealing to the senses.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_multi_image_message(image_urls, text_prompt):\n",
    "    \"\"\"Create message with multiple images\"\"\"\n",
    "    content = [{\"type\": \"text\", \"text\": text_prompt}]\n",
    "\n",
    "    for i, url in enumerate(image_urls):\n",
    "        content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": url}\n",
    "        })\n",
    "\n",
    "    return HumanMessage(content=content)\n",
    "\n",
    "\n",
    "# Example with multiple accessible images\n",
    "simple_images = [\n",
    "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\",\n",
    "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/scones.jpg\"\n",
    "]\n",
    "\n",
    "multi_image_message = create_multi_image_message(\n",
    "    simple_images,\n",
    "    \"Compare these two images. What are the differences in style, purpose, and visual elements?\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = llm.invoke([multi_image_message])\n",
    "    print(f\"Multi-image comparison: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Multi-image analysis error: {e}\")\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PRACTICAL APPLICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\nüõ†Ô∏è 5. Practical Multimodal Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImageAnalyzer:\n",
    "    \"\"\"A practical image analysis assistant\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def describe_image(self, image_url):\n",
    "        \"\"\"Get general description of an image\"\"\"\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"Provide a detailed description of this image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        )\n",
    "        return self.model.invoke([message]).content\n",
    "\n",
    "    def extract_text(self, image_url):\n",
    "        \"\"\"Extract and read text from an image (OCR)\"\"\"\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"Extract and transcribe any text visible in this image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        )\n",
    "        return self.model.invoke([message]).content\n",
    "\n",
    "    def identify_objects(self, image_url):\n",
    "        \"\"\"Identify objects and elements in an image\"\"\"\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"List and identify all objects, people, and elements visible in this image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        )\n",
    "        return self.model.invoke([message]).content\n",
    "\n",
    "    def analyze_mood(self, image_url):\n",
    "        \"\"\"Analyze the mood and emotional tone of an image\"\"\"\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"Analyze the mood, atmosphere, and emotional tone conveyed by this image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        )\n",
    "        return self.model.invoke([message]).content\n",
    "\n",
    "\n",
    "# Use the image analyzer\n",
    "analyzer = ImageAnalyzer(llm)\n",
    "\n",
    "# Test with a Google Cloud sample image\n",
    "test_image_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\n--- Image Analysis Results ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: The image shows a light blue, hard-shell suitcase standing upright on a white surface against a light gray background. The suitcase is rectangular with rounded edges and features a telescoping black handle extended at the top. The front of the suitcase has vertical grooves running from top to bottom, creating a textured appearance. On the left side, a black handle is visible. The suitcase has four black wheels, each with a multi-spoke design, allowing it to be easily maneuvered. The lighting is soft and even, highlighting the color and texture of the suitcase.\n",
      "Objects identified: Here's a list of the objects and elements visible in the image:\n",
      "\n",
      "*   **Suitcase:** The primary object is a light blue, hard-shell suitcase. It has vertical grooves on the front.\n",
      "*   **Handle (Retractable):** A black, retractable handle is extended from the top of the suitcase.\n",
      "*   **Handle (Side):** A black handle is visible on the side of the suitcase.\n",
      "*   **Wheels:** The suitcase has four wheels for mobility.\n",
      "*   **Background:** The background is a plain, light-colored wall.\n",
      "*   **Surface:** The suitcase is sitting on a white surface.\n",
      "Mood analysis: Here's an analysis of the mood, atmosphere, and emotional tone conveyed by the image:\n",
      "\n",
      "*   **Mood:** The mood is calm and serene. The soft blue color of the suitcase and the clean, minimalist background contribute to a sense of tranquility. There's a subtle feeling of anticipation, perhaps hinting at an upcoming journey.\n",
      "\n",
      "*   **Atmosphere:** The atmosphere is clean, modern, and somewhat sterile. The bright, even lighting and the plain backdrop give the image a sense of clinical precision. This suggests a focus on functionality and design.\n",
      "\n",
      "*   **Emotional Tone:** The emotional tone is one of quiet optimism and readiness. The suitcase, as a symbol of travel, evokes feelings of excitement and possibility. The clean and organized presentation suggests preparedness and a sense of control over the journey ahead. There's also a hint of sophistication and understated elegance in the design of the suitcase itself.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    description = analyzer.describe_image(test_image_url)\n",
    "    print(f\"Description: {description}\")\n",
    "except Exception as e:\n",
    "    print(f\"Description error: {e}\")\n",
    "\n",
    "try:\n",
    "    objects = analyzer.identify_objects(test_image_url)\n",
    "    print(f\"Objects identified: {objects}\")\n",
    "except Exception as e:\n",
    "    print(f\"Object identification error: {e}\")\n",
    "\n",
    "try:\n",
    "    mood = analyzer.analyze_mood(test_image_url)\n",
    "    print(f\"Mood analysis: {mood}\")\n",
    "except Exception as e:\n",
    "    print(f\"Mood analysis error: {e}\")\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BEST PRACTICES AND TIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\nüí° 6. Best Practices for Multimodal Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def demonstrate_best_practices():\n",
    "    \"\"\"Show best practices for multimodal applications\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Image Quality Tips:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Use clear, well-lit images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Ensure reasonable resolution (not too small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Avoid heavily compressed images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\n‚úÖ Prompt Design Tips:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Be specific about what you want to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Provide context when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Ask focused questions rather than general ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\n‚úÖ Error Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Always wrap image processing in try-catch blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Have fallback strategies for failed image loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Validate image URLs before processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\n‚úÖ Performance Tips:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Resize large images before encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Use appropriate image formats (JPEG for photos, PNG for graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Cache frequently analyzed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "demonstrate_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CHAIN WITH MULTIMODAL INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîó 7. Creating Chains with Multimodal Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain result: Here are the objects and items I can identify in the image:\n",
      "\n",
      "*   **Suitcase:** The main object in the image is a blue suitcase. It has a hard shell with vertical grooves.\n",
      "*   **Handle:** The suitcase has a retractable black handle on top for pulling it. There's also a smaller, black side handle for carrying.\n",
      "*   **Wheels:** The suitcase has four wheels at the bottom for easy rolling.\n",
      "*   **Background:** The suitcase is placed in front of a plain, light-colored background.\n",
      "*   **Surface:** The suitcase is sitting on a white surface.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a multimodal analysis chain\n",
    "def create_multimodal_chain():\n",
    "    \"\"\"Create a chain that processes image and text together\"\"\"\n",
    "\n",
    "    def process_multimodal_input(input_dict):\n",
    "        \"\"\"Process multimodal input and create appropriate message\"\"\"\n",
    "        text = input_dict[\"text\"]\n",
    "        image_url = input_dict[\"image_url\"]\n",
    "\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": text},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]\n",
    "        )\n",
    "        return [message]\n",
    "\n",
    "    from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "    # Create the multimodal chain\n",
    "    chain = RunnableLambda(process_multimodal_input) | llm | StrOutputParser()\n",
    "    return chain\n",
    "\n",
    "\n",
    "# Test the multimodal chain\n",
    "multimodal_chain = create_multimodal_chain()\n",
    "\n",
    "chain_input = {\n",
    "    \"text\": \"What objects and items can you identify in this image?\",\n",
    "    \"image_url\": \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    chain_result = multimodal_chain.invoke(chain_input)\n",
    "    print(f\"Chain result: {chain_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Chain processing error: {e}\")\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. KEY INFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\nüìã Key Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Gemini models support text + image inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Images can be provided via URL or base64 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Use HumanMessage with content list for multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Support for multiple images in single request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Combine with templates and chains for complex workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Always implement proper error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Consider image quality and format optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\nüéØ Next step: Learn about streaming responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö See: 07_streaming_responses.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
