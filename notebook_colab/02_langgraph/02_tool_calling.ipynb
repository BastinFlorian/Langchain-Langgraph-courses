{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langgraph langchain-google-genai python-dotenv\n",
    "\n",
    "\"\"\"\n",
    "LangGraph Tool Calling - Integrating Tools with StateGraph\n",
    "\n",
    "This script demonstrates:\n",
    "- Creating and binding tools to LLMs\n",
    "- Using ToolNode for automatic tool execution\n",
    "- Handling tool calls in StateGraph\n",
    "- Managing state with tool results\n",
    "- Error handling for tool execution\n",
    "\n",
    "Documentation: https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#tools\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is set\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    raise ValueError(\"Please set GOOGLE_API_KEY in your .env file\")\n",
    "\n",
    "print(\"=== LangGraph Tool Calling ===\\n\")\n",
    "\n",
    "# Section 1: Define Tools\n",
    "print(\"1. Define Tools\")\n",
    "print(\"-\" * 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_tip(bill_amount: float, tip_percentage: float = 18.0) -> str:\n",
    "    \"\"\"Calculate tip amount and total bill including tip.\n",
    "\n",
    "    Args:\n",
    "        bill_amount: The original bill amount\n",
    "        tip_percentage: Tip percentage (default 18%)\n",
    "\n",
    "    Returns:\n",
    "        String with tip calculation details\n",
    "    \"\"\"\n",
    "    tip_amount = bill_amount * (tip_percentage / 100)\n",
    "    total_amount = bill_amount + tip_amount\n",
    "\n",
    "    return f\"Bill: ${bill_amount:.2f}, Tip ({tip_percentage}%): ${tip_amount:.2f}, Total: ${total_amount:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def convert_temperature(temperature: float, from_unit: str = \"celsius\", to_unit: str = \"fahrenheit\") -> str:\n",
    "    \"\"\"Convert temperature between Celsius and Fahrenheit.\n",
    "\n",
    "    Args:\n",
    "        temperature: Temperature value to convert\n",
    "        from_unit: Source unit (\"celsius\" or \"fahrenheit\")\n",
    "        to_unit: Target unit (\"celsius\" or \"fahrenheit\")\n",
    "\n",
    "    Returns:\n",
    "        String with conversion result\n",
    "    \"\"\"\n",
    "    if from_unit.lower() == \"celsius\" and to_unit.lower() == \"fahrenheit\":\n",
    "        converted = (temperature * 9/5) + 32\n",
    "        return f\"{temperature}°C = {converted:.1f}°F\"\n",
    "    elif from_unit.lower() == \"fahrenheit\" and to_unit.lower() == \"celsius\":\n",
    "        converted = (temperature - 32) * 5/9\n",
    "        return f\"{temperature}°F = {converted:.1f}°C\"\n",
    "    else:\n",
    "        return f\"Invalid conversion: {from_unit} to {to_unit}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def word_count(text: str) -> str:\n",
    "    \"\"\"Count words, characters, and lines in text.\n",
    "\n",
    "    Args:\n",
    "        text: Text to analyze\n",
    "\n",
    "    Returns:\n",
    "        String with text statistics\n",
    "    \"\"\"\n",
    "    words = len(text.split())\n",
    "    chars = len(text)\n",
    "    chars_no_spaces = len(text.replace(\" \", \"\"))\n",
    "    lines = len(text.split(\"\\n\"))\n",
    "\n",
    "    return f\"Words: {words}, Characters: {chars}, Characters (no spaces): {chars_no_spaces}, Lines: {lines}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool list\n",
    "tools = [calculate_tip, convert_temperature, word_count]\n",
    "print(\n",
    "    f\"✓ Created {len(tools)} tools: calculate_tip, convert_temperature, word_count\")\n",
    "print()\n",
    "\n",
    "# Section 2: Initialize LLM with Tools\n",
    "print(\"2. Initialize LLM with Tools\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "print(\"✓ Bound tools to Gemini model\")\n",
    "print()\n",
    "\n",
    "# Section 3: Define State Schema\n",
    "print(\"3. Define State Schema\")\n",
    "print(\"-\" * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State schema for tool-calling agent\"\"\"\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✓ Created AgentState with messages using add_messages reducer\")\n",
    "print()\n",
    "\n",
    "# Section 4: Define Node Functions\n",
    "print(\"4. Define Node Functions\")\n",
    "print(\"-\" * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: AgentState) -> AgentState:\n",
    "    \"\"\"Node that calls the LLM with tool capabilities\"\"\"\n",
    "    print(f\"  → Calling model with {len(state['messages'])} messages\")\n",
    "\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    # Log if tools were called\n",
    "    if response.tool_calls:\n",
    "        print(f\"  → Model requested {len(response.tool_calls)} tool calls\")\n",
    "        for tool_call in response.tool_calls:\n",
    "            print(f\"    - {tool_call['name']}: {tool_call['args']}\")\n",
    "    else:\n",
    "        print(\"  → Model provided direct response (no tools)\")\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Conditional edge to determine next step\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # If the last message has tool calls, continue to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        print(\"  → Tool calls detected, routing to tools\")\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        print(\"  → No tool calls, ending conversation\")\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✓ Defined call_model and should_continue functions\")\n",
    "print()\n",
    "\n",
    "# Section 5: Create StateGraph with ToolNode\n",
    "print(\"5. Create StateGraph with ToolNode\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Create the tool node (automatically handles tool execution)\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Initialize workflow\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "print(\"✓ Created StateGraph with agent and tools nodes\")\n",
    "print()\n",
    "\n",
    "# Section 6: Add Edges\n",
    "print(\"6. Add Edges\")\n",
    "print(\"-\" * 15)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Conditional edge from agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After tools, go back to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "print(\"✓ Added edges: START → agent → tools → agent (loop)\")\n",
    "print(\"✓ Added conditional edge: agent → (tools/end)\")\n",
    "print()\n",
    "\n",
    "# Section 7: Compile and Test\n",
    "print(\"7. Compile and Test\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"✓ Graph compiled successfully!\")\n",
    "print()\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"Calculate a 20% tip on a $45.50 bill\",\n",
    "    \"Convert 25 degrees Celsius to Fahrenheit\",\n",
    "    \"Count the words in this sentence: 'LangGraph makes building AI agents much easier and more reliable.'\",\n",
    "    \"What's the weather like today?\",  # No tool needed\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_cases, 1):\n",
    "    print(f\"Test Case {i}: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Create initial state\n",
    "    initial_state = {\"messages\": [HumanMessage(content=query)]}\n",
    "\n",
    "    try:\n",
    "        # Run the graph\n",
    "        result = app.invoke(initial_state)\n",
    "\n",
    "        # Print conversation flow\n",
    "        print(\"Conversation:\")\n",
    "        for msg in result[\"messages\"]:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                print(f\"  Human: {msg.content}\")\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    print(\n",
    "                        f\"  AI: [Tool calls: {[tc['name'] for tc in msg.tool_calls]}]\")\n",
    "                else:\n",
    "                    print(f\"  AI: {msg.content}\")\n",
    "            elif isinstance(msg, ToolMessage):\n",
    "                print(f\"  Tool ({msg.name}): {msg.content}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        print()\n",
    "\n",
    "# Section 8: Understanding Tool Integration\n",
    "print(\"8. Understanding Tool Integration\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "print(\"Key concepts demonstrated:\")\n",
    "print(\"• Tools are defined using @tool decorator with type hints\")\n",
    "print(\"• LLM.bind_tools() enables the model to call tools\")\n",
    "print(\"• ToolNode automatically executes tool calls\")\n",
    "print(\"• Messages flow: Human → AI (with tool calls) → Tool results → AI (final response)\")\n",
    "print(\"• State management handles the entire conversation history\")\n",
    "print(\"• Conditional edges route based on whether tools are needed\")\n",
    "print()\n",
    "\n",
    "print(\"=== Tool Calling Complete! ===\")\n",
    "\n",
    "# TODO: Student Exercise\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TODO: Student Exercise - Math & File Operations Agent\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "Create a tool-calling agent with mathematical and text processing capabilities:\n",
    "\n",
    "1. Define these tools:\n",
    "   - calculate_average: Takes a list of numbers and returns the average\n",
    "   - find_prime_numbers: Takes a number n and returns all primes up to n\n",
    "   - text_statistics: Takes text and returns detailed stats (words, sentences, avg word length)\n",
    "   - generate_password: Takes length parameter and returns a secure password\n",
    "\n",
    "2. Create a StateGraph that:\n",
    "   - Uses these tools when appropriate\n",
    "   - Can handle multi-step calculations (e.g., \"Find primes up to 20, then calculate their average\")\n",
    "   - Provides helpful responses even when no tools are needed\n",
    "\n",
    "3. Test with queries like:\n",
    "   - \"Find all prime numbers up to 30\"\n",
    "   - \"Calculate the average of 15, 23, 8, 42, 19\"\n",
    "   - \"Analyze this text: 'The quick brown fox jumps over the lazy dog.'\"\n",
    "   - \"Generate a 12-character secure password\"\n",
    "   - \"What is the capital of France?\" (no tools needed)\n",
    "\n",
    "4. Observe how the agent decides when to use tools vs direct responses\n",
    "\n",
    "Hint: Use isinstance() to check message types and hasattr() to check for tool_calls\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
